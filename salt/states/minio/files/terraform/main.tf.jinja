# Generated by SaltStack for MinIO deployment
# This follows the STACK.md orchestration hierarchy

terraform {
  required_version = ">= 1.9"
  required_providers {
    nomad = {
      source  = "hashicorp/nomad"
      version = "~> 2.0"
    }
    consul = {
      source  = "hashicorp/consul"
      version = "~> 2.0"
    }
    vault = {
      source  = "hashicorp/vault"
      version = "~> 4.0"
    }
    random = {
      source  = "hashicorp/random"
      version = "~> 3.0"
    }
  }
}

# Provider configurations from pillar data
provider "nomad" {
  address = var.nomad_addr
}

provider "consul" {
  address = var.consul_addr
}

provider "vault" {
  address = var.vault_addr
  # Handle Vault unavailability gracefully
  skip_tls_verify = true
}

# Local variables for app-specific configuration
locals {
  app_name     = "{{ app_name }}"
  service_name = "minio-{{ app_name }}"
  {% if minio.get('use_cephfs', false) %}
  volume_type  = "cephfs"
  {% else %}
  volume_type  = "host"
  {% endif %}
}

# Generate secure credentials
resource "random_password" "minio_root_password" {
  length  = 32
  special = true
}

# Try to store credentials in Vault, but don't fail if unavailable
resource "vault_kv_secret_v2" "minio_root" {
  count               = var.skip_vault ? 0 : 1
  mount               = "kv"
  name                = "minio/{{ app_name }}"
  delete_all_versions = true
  data_json = jsonencode({
    MINIO_ROOT_USER     = var.minio_root_user
    MINIO_ROOT_PASSWORD = random_password.minio_root_password.result
  })
  
  lifecycle {
    ignore_changes = [data_json]
  }
}

# Fallback: Store credentials in Consul if Vault is unavailable
resource "consul_key_prefix" "minio_credentials" {
  count = var.skip_vault ? 1 : 0
  path_prefix = "minio/{{ app_name }}/"
  
  subkeys = {
    "root_user"     = var.minio_root_user
    "root_password" = random_password.minio_root_password.result
    "warning"       = "Vault unavailable - credentials stored in Consul. Migrate to Vault ASAP!"
  }
}

# Consul service registration with health checks
resource "consul_service" "minio_api" {
  name = local.service_name
  node = var.node_name
  port = var.api_port
  tags = {{ minio.get('consul_tags', ['minio', 'api', 's3']) | tojson }}
  
  check {
    check_id = "${local.service_name}-health"
    name     = "MinIO API Health Check"
    http     = "http://${var.node_address}:${var.api_port}/minio/health/live"
    method   = "GET"
    interval = "{{ minio.get('health_check_interval', '30s') }}"
    timeout  = "{{ minio.get('health_check_timeout', '5s') }}"
  }
  
  # Meta for Prometheus scraping
  meta = {
    prometheus_port = tostring(var.api_port)
    prometheus_path = "/minio/v2/metrics/cluster"
    datacenter      = var.datacenter
  }
}

# Console service registration
resource "consul_service" "minio_console" {
  name = "${local.service_name}-console"
  node = var.node_name
  port = var.console_port
  tags = concat({{ minio.get('consul_tags', ['minio', 'console', 'ui']) | tojson }}, ["console"])
  
  check {
    check_id = "${local.service_name}-console-health"
    name     = "MinIO Console Health Check"
    http     = "http://${var.node_address}:${var.console_port}"
    interval = "{{ minio.get('health_check_interval', '30s') }}"
    timeout  = "{{ minio.get('health_check_timeout', '5s') }}"
  }
}

# Deploy Nomad job
resource "nomad_job" "minio" {
  jobspec = templatefile("${path.module}/minio.nomad.hcl", {
    app_name       = local.app_name
    datacenter     = var.datacenter
    storage_path   = var.storage_path
    vault_addr     = var.vault_addr
    api_port       = var.api_port
    console_port   = var.console_port
    memory_limit   = var.memory_limit
    cpu_limit      = var.cpu_limit
    volume_type    = local.volume_type
    volume_source  = var.volume_source
    skip_vault     = var.skip_vault
    vault_path     = var.skip_vault ? "" : vault_kv_secret_v2.minio_root[0].path
    consul_path    = var.skip_vault ? consul_key_prefix.minio_credentials[0].path_prefix : ""
  })
  
  depends_on = [
    consul_service.minio_api,
    consul_service.minio_console
  ]
  
  # Prevent job updates from destroying the deployment
  lifecycle {
    create_before_destroy = true
  }
}

# Output deployment information
output "minio_api_endpoint" {
  value = "http://${var.node_address}:${var.api_port}"
}

output "minio_console_endpoint" {
  value = "http://${var.node_address}:${var.console_port}"
}

output "credentials_location" {
  value = var.skip_vault ? "consul kv get ${consul_key_prefix.minio_credentials[0].path_prefix}" : "vault kv get ${vault_kv_secret_v2.minio_root[0].path}"
}

output "nomad_job_id" {
  value = nomad_job.minio.id
}

output "deployment_status" {
  value = {
    vault_available = !var.skip_vault
    service_name    = local.service_name
    volume_type     = local.volume_type
  }
}